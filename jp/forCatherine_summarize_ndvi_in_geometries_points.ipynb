{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# import some helper functions\n",
    "from proc_helpers import buffer_point_polygon_overlay,pp_summarize_ndvi_with_qa_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'init': 'epsg:32636'}\n",
      "{'init': 'epsg:32736'}\n",
      "{'init': 'epsg:32736'}\n"
     ]
    }
   ],
   "source": [
    "points_shp = '../../gis/moved_locations.shp'\n",
    "extra_erase_shp = ['../../gis/VillplusGR.shp', '../../gis/Agin_Villages.shp']\n",
    "df = gpd.read_file(points_shp)\n",
    "print(df.crs)\n",
    "print(gpd.read_file(extra_erase_shp[0]).crs)\n",
    "print(gpd.read_file(extra_erase_shp[1]).crs)\n",
    "\n",
    "# ensure the points are in the same CRS as polygons... for some reason they are different\n",
    "df = df.to_crs(epsg='32736')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VillageNam</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>NewName</th>\n",
       "      <th>NewID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agincourt</td>\n",
       "      <td>BBBCE</td>\n",
       "      <td>Agincourt</td>\n",
       "      <td>01</td>\n",
       "      <td>POINT (323325.9884000002 7254571.9086)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agincourt</td>\n",
       "      <td>BBBCN</td>\n",
       "      <td>Agincourt</td>\n",
       "      <td>01</td>\n",
       "      <td>POINT (323793.302 7254205.93)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agincourt</td>\n",
       "      <td>BBBEH</td>\n",
       "      <td>Agincourt</td>\n",
       "      <td>01</td>\n",
       "      <td>POINT (323905.9172000003 7253881.413900001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agincourt</td>\n",
       "      <td>BBBEN</td>\n",
       "      <td>Agincourt</td>\n",
       "      <td>01</td>\n",
       "      <td>POINT (323416.6338000002 7253991.3725)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agincourt</td>\n",
       "      <td>BBBJY</td>\n",
       "      <td>Agincourt</td>\n",
       "      <td>01</td>\n",
       "      <td>POINT (324492.3450999995 7252748.390000001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VillageNam LocationID    NewName NewID  \\\n",
       "0  Agincourt      BBBCE  Agincourt    01   \n",
       "1  Agincourt      BBBCN  Agincourt    01   \n",
       "2  Agincourt      BBBEH  Agincourt    01   \n",
       "3  Agincourt      BBBEN  Agincourt    01   \n",
       "4  Agincourt      BBBJY  Agincourt    01   \n",
       "\n",
       "                                      geometry  \n",
       "0       POINT (323325.9884000002 7254571.9086)  \n",
       "1                POINT (323793.302 7254205.93)  \n",
       "2  POINT (323905.9172000003 7253881.413900001)  \n",
       "3       POINT (323416.6338000002 7253991.3725)  \n",
       "4  POINT (324492.3450999995 7252748.390000001)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.crs == {'init':'epsg:32734'}\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\south_africa\\south_africa_landsat\\jp\\proc_helpers.py:341: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['geometry'] = df['geometry'].buffer(buff_dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'init': 'epsg:32736'} {'init': 'epsg:32736', 'no_defs': True}\n"
     ]
    }
   ],
   "source": [
    "# buff_erase_df = create_buffer_point_polygon_overlay(df, method='difference', num_points=2)\n",
    "\n",
    "# use this one for the points specified in the shapefile (_v2)\n",
    "# buff_erase_df = create_buffer_point_polygon_overlay_v2(df, method='difference') \n",
    "# buff_erase_df.crs = {'init' :'epsg:32736'}\n",
    "\n",
    "# use this one to erase a list of shapefiles from the buffered points. Those shapefiles must have same CRS\n",
    "#buff_erase_df = create_buffer_point_polygon_overlay_v3(df, method='difference', num_points_fld='NUMHH', erase_shp_files=[extra_erase_shp]) \n",
    "\n",
    "# use this one if providing a data frame of points and to erase a list of shapefiles from buffered points.\n",
    "test_df = df[df['NewID'].astype('int') < 3]\n",
    "buff_erase_df = buffer_point_polygon_overlay(test_df, erase_shp_files=extra_erase_shp)\n",
    "\n",
    "buff_erase_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2526, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['NewID'].astype('int') < 3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '23', '02', '03', '04', '24', '25', '26', '27', '05', '12',\n",
       "       '15', '06', '07', '11', '08', '19', '20', '21', '09', '10', '18',\n",
       "       '31', '36', '29', '13', '14', '17', '30', '28', '16'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will show you how many geometries now exist for processing\n",
    "df['NewID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the NDVI and pixel_qa raster paths and check that they match up\n",
    "### specify the qa_dir and ndvi_dir with trailing '/' character or the functions will not run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dir = '../landsat/test/qa/'\n",
    "ndvi_dir = '../landsat/test/ndvi/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg_df: 32736, epsg_raster: 32636\n",
      "epsg_df: {'init': 'epsg:32636', 'no_defs': True}, epsg_raster: 32636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\projects\\RD\\south_africa\\jp\\proc_helpers.py:534: UserWarning: Warning: converting a masked element to nan.\n",
      "  ndvi_df = geo_df.join(pd.DataFrame(np.array(all_vals).T, columns=landsat_columns), how='outer')\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "test_function_pp = pp_summarize_ndvi_with_qa_dir(ndvi_dir, qa_dir, buff_erase_df, 'median')\n",
    "t1 = time.time()\n",
    "\n",
    "## the number of cores and geometries will change...\n",
    "#print('parallel across 6 cores and 28 geometries is: {}'.format(t1-t0))\n",
    "\n",
    "\n",
    "## don't run this, it operates in serial and is slow\n",
    "# t0 = time.time()\n",
    "# test_function = summarize_ndvi_with_qa_dir(ndvi_dir, qa_dir, buff_erase_df, 'median')\n",
    "# t1 = time.time()\n",
    "# print('serial and 28 geometries is: {}'.format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the output filename to your desire\n",
    "test_function_pp.to_crs(epsg=32736).to_file('test_landsat_summaries_1997_2017_median_maskCloudWater.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# everything below here is testing and doesn't need to run\n",
    "## test number of points for scaling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import time\n",
    "\n",
    "times = []\n",
    "total_points = []\n",
    "num_points = (1,2,3,4,5,6,7)\n",
    "for npoints in num_points:\n",
    "    \n",
    "    buff_erase_df = create_buffer_point_polygon_overlay(df, method='difference', num_points=npoints)\n",
    "    buff_erase_df.crs = {'init' :'epsg:32736'}\n",
    "    \n",
    "    t0 = time.time()\n",
    "    test_function_pp = pp_summarize_ndvi_with_qa_dir(ndvi_dir, qa_dir, buff_erase_df, 'median')\n",
    "    t1 = time.time()\n",
    "    \n",
    "    times.append(t1-t0)\n",
    "    total_points.append(buff_erase_df.shape[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(total_points, times)\n",
    "plt.xlabel(\"num_points\")\n",
    "plt.ylabel(\"processing time across 6 cores (s)\")\n",
    "\n",
    "locs, labels = plt.xticks()           # Get locations and labels\n",
    "plt.xticks(total_points, total_points)  # Set locations and labels\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from scipy.stats import linregress\n",
    "slope, intercept, r_value, p_value, std_err = linregress(total_points, times)\n",
    "slope, intercept, r_value, p_value, std_err"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bigtime = slope*33000 + intercept\n",
    "bigtime/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
